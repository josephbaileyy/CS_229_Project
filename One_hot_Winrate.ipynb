{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfL9zdVZdzu1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import io\n",
        "\n",
        "url='https://drive.google.com/file/d/1IjIEhLc9n8eLKeY-yh_YigKVWbhgGBsN/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "result_11 = df.loc[11::12, ['result','pick1', 'pick2', 'pick3', 'pick4', 'pick5']]\n",
        "result_10 = df.loc[10::12, ['result','pick1', 'pick2', 'pick3', 'pick4', 'pick5']]\n",
        "\n",
        "merged_result = pd.concat([result_10, result_11])\n",
        "merged_result = merged_result.sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['font.family'] = 'serif'\n",
        "\n",
        "filtered_df = df.loc[0:len(df), ['playername']].dropna()\n",
        "filtered_df = filtered_df[filtered_df['playername'] != \"unknown player\"]\n",
        "\n",
        "player_counts = filtered_df.value_counts()\n",
        "occurrence_counts = player_counts.value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(occurrence_counts.index, occurrence_counts.values, color='#8C1515')\n",
        "plt.title(\"Player Occurrence Counts\", fontsize=16)\n",
        "plt.xlabel(\"Number of Occurrences\", fontsize=12)\n",
        "plt.ylabel(\"Number of Players\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0d5qlu-LR6SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "player_wr = {}\n",
        "\n",
        "player1 = df.loc[0::12, ['playerid','champion', 'result']]\n",
        "player2 = df.loc[1::12, ['playerid','champion', 'result']]\n",
        "player3 = df.loc[2::12, ['playerid','champion', 'result']]\n",
        "player4 = df.loc[3::12, ['playerid','champion', 'result']]\n",
        "player5 = df.loc[4::12, ['playerid','champion', 'result']]\n",
        "player6 = df.loc[5::12, ['playerid','champion', 'result']]\n",
        "player7 = df.loc[6::12, ['playerid','champion', 'result']]\n",
        "player8 = df.loc[7::12, ['playerid','champion', 'result']]\n",
        "player9 = df.loc[8::12, ['playerid','champion', 'result']]\n",
        "player10 = df.loc[9::12, ['playerid','champion', 'result']]\n",
        "player_results = pd.concat([player1, player2, player3, player4, player5, player6, player7, player8, player9, player10])\n",
        "player_results = player_results.sort_index()\n",
        "player_results[:10]\n",
        "\n",
        "for index, row in player_results.iterrows():\n",
        "  player = row['playerid']\n",
        "  if player not in player_wr:\n",
        "    player_wr[player] = {}\n",
        "  champ = row['champion']\n",
        "  if champ not in player_wr[player]:\n",
        "    player_wr[player][champ] = [0, 0]\n",
        "  player_wr[player][champ][0] += row['result']\n",
        "  player_wr[player][champ][1] += 1\n",
        "\n",
        "print(player_wr['oe:player:e1edfc5cea461399a63cb813cf795cc'])"
      ],
      "metadata": {
        "id": "7wS4KvKoqM_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "league_champions = [\n",
        "    \"Aatrox\", \"Ahri\", \"Akali\", \"Akshan\", \"Alistar\", \"Amumu\", \"Anivia\", \"Annie\", \"Aphelios\", \"Ashe\",\n",
        "    \"Aurelion Sol\", \"Azir\", \"Bard\", \"Bel'Veth\", \"Blitzcrank\", \"Brand\", \"Braum\", \"Caitlyn\", \"Camille\",\n",
        "    \"Cassiopeia\", \"Cho'Gath\", \"Corki\", \"Darius\", \"Diana\", \"Dr. Mundo\", \"Draven\", \"Ekko\", \"Elise\",\n",
        "    \"Evelynn\", \"Ezreal\", \"Fiddlesticks\", \"Fiora\", \"Fizz\", \"Galio\", \"Gangplank\", \"Garen\", \"Gnar\",\n",
        "    \"Gragas\", \"Graves\", \"Gwen\", \"Hecarim\", \"Heimerdinger\", \"Illaoi\", \"Irelia\", \"Ivern\", \"Janna\",\n",
        "    \"Jarvan IV\", \"Jax\", \"Jayce\", \"Jhin\", \"Jinx\", \"K'Sante\", \"Kai'Sa\", \"Kalista\", \"Karma\", \"Karthus\",\n",
        "    \"Kassadin\", \"Katarina\", \"Kayle\", \"Kayn\", \"Kennen\", \"Kha'Zix\", \"Kindred\", \"Kled\", \"Kog'Maw\", \"LeBlanc\",\n",
        "    \"Lee Sin\", \"Leona\", \"Lillia\", \"Lissandra\", \"Lucian\", \"Lulu\", \"Lux\", \"Malphite\", \"Malzahar\",\n",
        "    \"Maokai\", \"Master Yi\", \"Milio\", \"Miss Fortune\", \"Mordekaiser\", \"Morgana\", \"Naafiri\", \"Nami\",\n",
        "    \"Nasus\", \"Nautilus\", \"Neeko\", \"Nidalee\", \"Nilah\", \"Nocturne\", \"Nunu & Willump\", \"Olaf\", \"Orianna\",\n",
        "    \"Ornn\", \"Pantheon\", \"Poppy\", \"Pyke\", \"Qiyana\", \"Quinn\", \"Rakan\", \"Rammus\", \"Rek'Sai\", \"Rell\",\n",
        "    \"Renata Glasc\", \"Renekton\", \"Rengar\", \"Riven\", \"Rumble\", \"Ryze\", \"Samira\", \"Sejuani\", \"Senna\",\n",
        "    \"Seraphine\", \"Sett\", \"Shaco\", \"Shen\", \"Shyvana\", \"Singed\", \"Sion\", \"Sivir\", \"Skarner\", \"Sona\",\n",
        "    \"Soraka\", \"Swain\", \"Sylas\", \"Syndra\", \"Tahm Kench\", \"Taliyah\", \"Talon\", \"Taric\", \"Teemo\",\n",
        "    \"Thresh\", \"Tristana\", \"Trundle\", \"Tryndamere\", \"Twisted Fate\", \"Twitch\", \"Udyr\", \"Urgot\",\n",
        "    \"Varus\", \"Vayne\", \"Veigar\", \"Vel'Koz\", \"Vex\", \"Vi\", \"Viego\", \"Viktor\", \"Vladimir\", \"Volibear\",\n",
        "    \"Warwick\", \"Wukong\", \"Xayah\", \"Xerath\", \"Xin Zhao\", \"Yasuo\", \"Yone\", \"Yorick\", \"Yuumi\",\n",
        "    \"Zac\", \"Zed\", \"Zeri\", \"Ziggs\", \"Zilean\", \"Zoe\", \"Zyra\"\n",
        "]\n",
        "champ_cols = ['pick1', 'pick2', 'pick3', 'pick4', 'pick5']\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "for index, row in merged_result.iterrows():\n",
        "    comp = [row['pick1'], row['pick2'], row['pick3'], row['pick4'], row['pick5']]\n",
        "    x = []\n",
        "    for champ in league_champions:\n",
        "        if champ in comp:\n",
        "            if index % 12 == 10:\n",
        "                for i in range(index - 10, index - 5):\n",
        "                    if df.iloc[i]['champion'] == champ:\n",
        "                        x.append(player_wr[df.iloc[i]['playerid']][champ][0] / player_wr[df.iloc[i]['playerid']][champ][1])\n",
        "            else:\n",
        "                for i in range(index - 6, index - 1):\n",
        "                    if df.iloc[i]['champion'] == champ:\n",
        "                        x.append(player_wr[df.iloc[i]['playerid']][champ][0] / player_wr[df.iloc[i]['playerid']][champ][1])\n",
        "        else:\n",
        "            x.append(0)\n",
        "    if len(x) == 164:\n",
        "      xs.append(x)\n",
        "      ys.append(row['result'])\n"
      ],
      "metadata": {
        "id": "wF-weQQW94Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, log_loss, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# calculate precision and recall\n",
        "precisionLR, recallLR, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "\n",
        "# auc\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')\n"
      ],
      "metadata": {
        "id": "2SRndB8l1JDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# calculate precision and recall\n",
        "precisionRF, recallRF, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')"
      ],
      "metadata": {
        "id": "hLnVMjM-jN6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_reg = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_reg.fit(X_train, y_train)\n",
        "\n",
        "y_prob = gb_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "y_pred = gb_reg.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "precisionGB, recallGB, _ = precision_recall_curve(y_test, y_prob)\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')"
      ],
      "metadata": {
        "id": "0iUQV76H1JDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch > 5:\n",
        "        return lr * 0.5  # Reduce LR after 5 epochs\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "def create_more_complex_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Input(shape=(xs.shape[1],)))\n",
        "\n",
        "    # First Hidden Layer\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Second Hidden Layer\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Third Hidden Layer\n",
        "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_more_complex_model()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=5,          # Stop after 5 epochs without improvement\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "# visualize training results\n",
        "# Plot accuracy\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs', fontsize='20')\n",
        "plt.ylabel('Accuracy', fontsize='20')\n",
        "plt.legend(fontsize='14')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs',fontsize='20')\n",
        "plt.ylabel('Loss', fontsize='20')\n",
        "plt.legend(fontsize='14')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yllMl6Exkosx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# Calculate F1 Score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Calculate precision and recall\n",
        "precisionNN, recallNN, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"AUC: {auc:.2f}\")"
      ],
      "metadata": {
        "id": "X08p6lgMlNEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the precision-recall curve\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recallLR, precisionLR, label='LR', color='#175E54')\n",
        "plt.plot(recallRF, precisionRF, label='RF', color='#8C1515')\n",
        "plt.plot(recallGB, precisionGB, label='GB', color='#4298B5')\n",
        "plt.plot(recallNN, precisionNN, label='NN', color='#E98300')\n",
        "\n",
        "\n",
        "plt.xlabel('Recall', fontsize='20')\n",
        "plt.ylabel('Precision', fontsize='20')\n",
        "plt.legend(fontsize='16')\n",
        "plt.tight_layout()\n",
        "plt.savefig('onehotwr.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dSFsqegGmT2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}