{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfL9zdVZdzu1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "url='https://drive.google.com/file/d/1IjIEhLc9n8eLKeY-yh_YigKVWbhgGBsN/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "result_11 = df.loc[11::12, ['result', 'side', 'pick1', 'pick2', 'pick3', 'pick4', 'pick5', 'ban1', 'ban2', 'ban3', 'ban4', 'ban5']]\n",
        "result_10 = df.loc[10::12, ['result', 'side', 'pick1', 'pick2', 'pick3', 'pick4', 'pick5', 'ban1', 'ban2', 'ban3', 'ban4', 'ban5']]\n",
        "\n",
        "merged_result = pd.concat([result_10, result_11])\n",
        "merged_result = merged_result.sort_index()\n",
        "merged_result = merged_result.reset_index(level=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4_qXWnsTfwI"
      },
      "outputs": [],
      "source": [
        "def clean_data(data):\n",
        "    rows_to_drop = set()\n",
        "\n",
        "    for i in range(0, len(data), 2):\n",
        "        # Check both rows in the pair (team1 and team2)\n",
        "        if data.iloc[i, 1:].isnull().any() or data.iloc[i + 1, 1:].isnull().any():\n",
        "            rows_to_drop.add(i)\n",
        "            rows_to_drop.add(i + 1)\n",
        "\n",
        "    # Drop identified rows\n",
        "    cleaned_data = data.drop(rows_to_drop).reset_index(drop = True)\n",
        "    return cleaned_data\n",
        "\n",
        "merged_result = clean_data(merged_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQaciRIrjMLh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(10)\n",
        "n_matches = int(len(merged_result) / 2)\n",
        "print(int(0.8 * n_matches))\n",
        "all_indices = [i for i in range(n_matches)]\n",
        "train_indices = random.sample(all_indices, int(0.8 * n_matches))\n",
        "train_indices.sort()\n",
        "print(train_indices)\n",
        "\n",
        "df_train_indices = []\n",
        "for x in train_indices:\n",
        "    df_train_indices.append(merged_result.iloc[2 * x]['index'] // 12)\n",
        "print(df_train_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wS4KvKoqM_q"
      },
      "outputs": [],
      "source": [
        "# Finding player stats on each champ\n",
        "player_champ_wr = {}\n",
        "player_career_wr = {}\n",
        "champ_wr = {}\n",
        "\n",
        "player1 = df.loc[0::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player2 = df.loc[1::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player3 = df.loc[2::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player4 = df.loc[3::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player5 = df.loc[4::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player6 = df.loc[5::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player7 = df.loc[6::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player8 = df.loc[7::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player9 = df.loc[8::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player10 = df.loc[9::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player_results = pd.concat([player1, player2, player3, player4, player5, player6, player7, player8, player9, player10])\n",
        "player_results = player_results.sort_index()\n",
        "player_results[:10]\n",
        "\n",
        "for index, row in player_results.iterrows():\n",
        "    if index // 12 in df_train_indices:\n",
        "        player = row['playerid']\n",
        "        if player not in player_career_wr:\n",
        "            player_career_wr[player] = [0, 0]\n",
        "        player_career_wr[player][0] += row['result']\n",
        "        player_career_wr[player][1] += 1\n",
        "\n",
        "        if player not in player_champ_wr:\n",
        "          player_champ_wr[player] = {}\n",
        "\n",
        "        champ = row['champion']\n",
        "        if champ not in player_champ_wr[player]:\n",
        "          player_champ_wr[player][champ] = [0, 0]\n",
        "        player_champ_wr[player][champ][0] += row['result']\n",
        "        player_champ_wr[player][champ][1] += 1\n",
        "\n",
        "        if champ not in champ_wr:\n",
        "          champ_wr[champ] = [0, 0]\n",
        "        champ_wr[champ][0] += row['result']\n",
        "        champ_wr[champ][1] += 1\n",
        "\n",
        "print(player_champ_wr['oe:player:e1edfc5cea461399a63cb813cf795cc'])\n",
        "print(champ_wr)\n",
        "print(player_career_wr['oe:player:e1edfc5cea461399a63cb813cf795cc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3yxgC56uBw2"
      },
      "outputs": [],
      "source": [
        "print(len(player_career_wr.keys()))\n",
        "print(champ_wr.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF-weQQW94Pq"
      },
      "outputs": [],
      "source": [
        "league_champions = [ # Not all champs included yet\n",
        "    \"Aatrox\", \"Ahri\", \"Akali\", \"Akshan\", \"Alistar\", \"Ambessa\", \"Amumu\", \"Anivia\", \"Annie\", \"Aphelios\", \"Ashe\",\n",
        "    \"Aurelion Sol\", \"Aurora\", \"Azir\", \"Bard\", \"Bel'Veth\", \"Blitzcrank\", \"Brand\", \"Braum\", \"Briar\", \"Caitlyn\", \"Camille\",\n",
        "    \"Cassiopeia\", \"Cho'Gath\", \"Corki\", \"Darius\", \"Diana\", \"Dr. Mundo\", \"Draven\", \"Ekko\", \"Elise\",\n",
        "    \"Evelynn\", \"Ezreal\", \"Fiddlesticks\", \"Fiora\", \"Fizz\", \"Galio\", \"Gangplank\", \"Garen\", \"Gnar\",\n",
        "    \"Gragas\", \"Graves\", \"Gwen\", \"Hecarim\", \"Heimerdinger\", \"Hwei\", \"Illaoi\", \"Irelia\", \"Ivern\", \"Janna\",\n",
        "    \"Jarvan IV\", \"Jax\", \"Jayce\", \"Jhin\", \"Jinx\", \"K'Sante\", \"Kai'Sa\", \"Kalista\", \"Karma\", \"Karthus\",\n",
        "    \"Kassadin\", \"Katarina\", \"Kayle\", \"Kayn\", \"Kennen\", \"Kha'Zix\", \"Kindred\", \"Kled\", \"Kog'Maw\", \"LeBlanc\",\n",
        "    \"Lee Sin\", \"Leona\", \"Lillia\", \"Lissandra\", \"Lucian\", \"Lulu\", \"Lux\", \"Malphite\", \"Malzahar\",\n",
        "    \"Maokai\", \"Master Yi\", \"Milio\", \"Miss Fortune\", \"Mordekaiser\", \"Morgana\", \"Naafiri\", \"Nami\",\n",
        "    \"Nasus\", \"Nautilus\", \"Neeko\", \"Nidalee\", \"Nilah\", \"Nocturne\", \"Nunu & Willump\", \"Olaf\", \"Orianna\",\n",
        "    \"Ornn\", \"Pantheon\", \"Poppy\", \"Pyke\", \"Qiyana\", \"Quinn\", \"Rakan\", \"Rammus\", \"Rek'Sai\", \"Rell\",\n",
        "    \"Renata Glasc\", \"Renekton\", \"Rengar\", \"Riven\", \"Rumble\", \"Ryze\", \"Samira\", \"Sejuani\", \"Senna\",\n",
        "    \"Seraphine\", \"Sett\", \"Shaco\", \"Shen\", \"Shyvana\", \"Singed\", \"Sion\", \"Sivir\", \"Skarner\", \"Smolder\", \"Sona\",\n",
        "    \"Soraka\", \"Swain\", \"Sylas\", \"Syndra\", \"Tahm Kench\", \"Taliyah\", \"Talon\", \"Taric\", \"Teemo\",\n",
        "    \"Thresh\", \"Tristana\", \"Trundle\", \"Tryndamere\", \"Twisted Fate\", \"Twitch\", \"Udyr\", \"Urgot\",\n",
        "    \"Varus\", \"Vayne\", \"Veigar\", \"Vel'Koz\", \"Vex\", \"Vi\", \"Viego\", \"Viktor\", \"Vladimir\", \"Volibear\",\n",
        "    \"Warwick\", \"Wukong\", \"Xayah\", \"Xerath\", \"Xin Zhao\", \"Yasuo\", \"Yone\", \"Yorick\", \"Yuumi\",\n",
        "    \"Zac\", \"Zed\", \"Zeri\", \"Ziggs\", \"Zilean\", \"Zoe\", \"Zyra\"\n",
        "]\n",
        "champ_cols = ['pick1', 'pick2', 'pick3', 'pick4', 'pick5']\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "modelW2V = Word2Vec.load(\"champion_embeddings-2.model\")\n",
        "def get_team_embedding(team, model):\n",
        "    return np.mean([model.wv[champion] for champion in team], axis=0)\n",
        "\n",
        "for index1, row in merged_result.iterrows():\n",
        "    if merged_result.iloc[index1]['index'] % 12 == 11:\n",
        "        x = []\n",
        "        teams = [[],[]]\n",
        "        for k in range(2):\n",
        "            index = merged_result.iloc[index1]['index'] - k\n",
        "            comp = [df.iloc[index]['pick1'], df.iloc[index]['pick2'], df.iloc[index]['pick3'], df.iloc[index]['pick4'], df.iloc[index]['pick5']]\n",
        "#            print(comp)\n",
        "            bans = [df.iloc[index]['ban1'], df.iloc[index]['ban2'], df.iloc[index]['ban3'], df.iloc[index]['ban4'], df.iloc[index]['ban5']]\n",
        "            teams[k] = comp\n",
        "\n",
        "            for i in range(5):\n",
        "                champ = comp[i]\n",
        "                if index % 12 == 10:\n",
        "                    for j in range(index - 10, index - 5):\n",
        "\n",
        "                        if df.iloc[j]['champion'] == champ:\n",
        "                            player = df.iloc[j]['playerid']\n",
        "                            if player in player_champ_wr and champ in player_champ_wr[player]:\n",
        "                                x.append(player_champ_wr[df.iloc[j]['playerid']][champ][0] / player_champ_wr[df.iloc[j]['playerid']][champ][1])\n",
        "                                x.append(player_champ_wr[df.iloc[j]['playerid']][champ][1])\n",
        "                            elif index // 12 in df_train_indices:\n",
        "                                print(df.iloc[index])\n",
        "                            if player in player_career_wr:\n",
        "                                x.append(player_career_wr[df.iloc[j]['playerid']][0] / player_career_wr[df.iloc[j]['playerid']][1])\n",
        "                            elif index // 12 in df_train_indices:\n",
        "                                print(df.iloc[index])\n",
        "                            if champ in champ_wr:\n",
        "                                x.append(champ_wr[champ][0] / champ_wr[champ][1])\n",
        "                            elif index // 12 in df_train_indices:\n",
        "                                print(df.iloc[index])\n",
        "                else:\n",
        "                    for j in range(index - 6, index - 1):\n",
        "                        if df.iloc[j]['champion'] == champ:\n",
        "                            player = df.iloc[j]['playerid']\n",
        "                            if player in player_champ_wr and champ in player_champ_wr[player]:\n",
        "                                x.append(player_champ_wr[df.iloc[j]['playerid']][champ][0] / player_champ_wr[df.iloc[j]['playerid']][champ][1])\n",
        "                                x.append(player_champ_wr[df.iloc[j]['playerid']][champ][1])\n",
        "                            elif index // 12 in df_train_indices:\n",
        "                                print(df.iloc[index])\n",
        "                            if player in player_career_wr:\n",
        "                                x.append(player_career_wr[df.iloc[j]['playerid']][0] / player_career_wr[df.iloc[j]['playerid']][1])\n",
        "                            elif index // 12 in df_train_indices:\n",
        "                                print(df.iloc[index])\n",
        "                            if champ in champ_wr:\n",
        "                                x.append(champ_wr[champ][0] / champ_wr[champ][1])\n",
        "                            elif index // 12 in df_train_indices:\n",
        "                                print(df.iloc[index])\n",
        "\n",
        "\n",
        "            for i in range(5):\n",
        "                if bans[i] not in champ_wr:\n",
        "                    x.append(0.5)\n",
        "                else:\n",
        "                    x.append(champ_wr[bans[i]][0] / champ_wr[bans[i]][1])\n",
        "        # adding pre-trained embeddings\n",
        "        team1_embedding = get_team_embedding(teams[0], modelW2V)\n",
        "        team2_embedding = get_team_embedding(teams[1], modelW2V)\n",
        "        x = np.concatenate([x, team1_embedding, team2_embedding])\n",
        "\n",
        "        if len(x) == 66:\n",
        "          if len(xs) % 1000 == 0: print(len(xs))\n",
        "          xs.append([merged_result.iloc[index1]['index'] // 12, x])\n",
        "          ys.append(row['result'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zli762QB92N8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "for i in range(len(xs)):\n",
        "    if xs[i][0] in train_indices:\n",
        "        X_train.append(xs[i][1])\n",
        "        y_train.append(ys[i])\n",
        "    else:\n",
        "        X_test.append(xs[i][1])\n",
        "        y_test.append(ys[i])\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, log_loss, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# calculate precision and recall\n",
        "precisionLR, recallLR, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "\n",
        "# auc\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')\n"
      ],
      "metadata": {
        "id": "hXQZkv1RE9hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# calculate precision and recall\n",
        "precisionRF, recallRF, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')"
      ],
      "metadata": {
        "id": "hLnVMjM-jN6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_reg = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_reg.fit(X_train, y_train)\n",
        "\n",
        "y_prob = gb_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "y_pred = gb_reg.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "precisionGB, recallGB, _ = precision_recall_curve(y_test, y_prob)\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')"
      ],
      "metadata": {
        "id": "u-AF3B1UGIvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch > 5:\n",
        "        return lr * 0.5  # Reduce LR after 5 epochs\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "xs = pd.DataFrame(xs)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "def create_more_complex_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Input(shape=(xs.shape[1],)))\n",
        "\n",
        "    # First Hidden Layer\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Second Hidden Layer\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Third Hidden Layer\n",
        "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_more_complex_model()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "# visualize training results\n",
        "# Plot accuracy\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs', fontsize='20')\n",
        "plt.ylabel('Accuracy', fontsize='20')\n",
        "plt.legend(fontsize='14')\n",
        "plt.savefig('embacc.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs',fontsize='20')\n",
        "plt.ylabel('Loss', fontsize='20')\n",
        "plt.legend(fontsize='14')\n",
        "plt.savefig('embloss.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yllMl6Exkosx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
        "\n",
        "# Calculate F1 Score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# Calculate precision and recall\n",
        "precisionNN, recallNN, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"AUC: {auc:.2f}\")"
      ],
      "metadata": {
        "id": "X08p6lgMlNEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the precision-recall curve\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recallLR, precisionLR, label='LR', color='#175E54')\n",
        "plt.plot(recallRF, precisionRF, label='RF', color='#8C1515')\n",
        "plt.plot(recallGB, precisionGB, label='GB', color='#4298B5')\n",
        "plt.plot(recallNN, precisionNN, label='NN', color='#E98300')\n",
        "\n",
        "\n",
        "plt.xlabel('Recall', fontsize='20')\n",
        "plt.ylabel('Precision', fontsize='20')\n",
        "plt.legend(fontsize='16')\n",
        "plt.tight_layout()\n",
        "plt.savefig('vectoremb.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dSFsqegGmT2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}