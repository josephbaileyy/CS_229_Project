{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HjLlDoJQ0k80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfL9zdVZdzu1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "url='https://drive.google.com/file/d/1IjIEhLc9n8eLKeY-yh_YigKVWbhgGBsN/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "result_11 = df.loc[11::12, ['result', 'side', 'pick1', 'pick2', 'pick3', 'pick4', 'pick5', 'ban1', 'ban2', 'ban3', 'ban4', 'ban5']]\n",
        "result_10 = df.loc[10::12, ['result', 'side', 'pick1', 'pick2', 'pick3', 'pick4', 'pick5', 'ban1', 'ban2', 'ban3', 'ban4', 'ban5']]\n",
        "\n",
        "merged_result = pd.concat([result_10, result_11])\n",
        "merged_result = merged_result.sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding player stats on each champ\n",
        "player_champ_wr = {}\n",
        "player_career_wr = {}\n",
        "champ_wr = {}\n",
        "\n",
        "player1 = df.loc[0::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player2 = df.loc[1::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player3 = df.loc[2::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player4 = df.loc[3::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player5 = df.loc[4::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player6 = df.loc[5::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player7 = df.loc[6::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player8 = df.loc[7::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player9 = df.loc[8::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player10 = df.loc[9::12, ['playerid','champion', 'result', 'kills', 'deaths', 'assists']]\n",
        "player_results = pd.concat([player1, player2, player3, player4, player5, player6, player7, player8, player9, player10])\n",
        "player_results = player_results.sort_index()\n",
        "player_results[:10]\n",
        "\n",
        "for index, row in player_results.iterrows():\n",
        "  player = row['playerid']\n",
        "  if player not in player_champ_wr:\n",
        "    player_champ_wr[player] = {}\n",
        "\n",
        "  champ = row['champion']\n",
        "  if champ not in player_champ_wr[player]:\n",
        "    player_champ_wr[player][champ] = [0, 0]\n",
        "\n",
        "  player_champ_wr[player][champ][0] += row['result']\n",
        "  player_champ_wr[player][champ][1] += 1\n",
        "\n",
        "  if champ not in champ_wr:\n",
        "    champ_wr[champ] = [0, 0]\n",
        "  champ_wr[champ][0] += row['result']\n",
        "  champ_wr[champ][1] += 1\n",
        "\n",
        "for index, row in player_results.iterrows():\n",
        "  player = row['playerid']\n",
        "  if player not in player_career_wr:\n",
        "    player_career_wr[player] = [0, 0]\n",
        "  player_career_wr[player][0] += row['result']\n",
        "  player_career_wr[player][1] += 1"
      ],
      "metadata": {
        "id": "7wS4KvKoqM_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "league_champions = [\n",
        "    \"Aatrox\", \"Ahri\", \"Akali\", \"Akshan\", \"Alistar\", \"Ambessa\", \"Amumu\", \"Anivia\", \"Annie\", \"Aphelios\", \"Ashe\",\n",
        "    \"Aurelion Sol\", \"Aurora\", \"Azir\", \"Bard\", \"Bel'Veth\", \"Blitzcrank\", \"Brand\", \"Braum\", \"Briar\", \"Caitlyn\", \"Camille\",\n",
        "    \"Cassiopeia\", \"Cho'Gath\", \"Corki\", \"Darius\", \"Diana\", \"Dr. Mundo\", \"Draven\", \"Ekko\", \"Elise\",\n",
        "    \"Evelynn\", \"Ezreal\", \"Fiddlesticks\", \"Fiora\", \"Fizz\", \"Galio\", \"Gangplank\", \"Garen\", \"Gnar\",\n",
        "    \"Gragas\", \"Graves\", \"Gwen\", \"Hecarim\", \"Heimerdinger\", \"Hwei\", \"Illaoi\", \"Irelia\", \"Ivern\", \"Janna\",\n",
        "    \"Jarvan IV\", \"Jax\", \"Jayce\", \"Jhin\", \"Jinx\", \"K'Sante\", \"Kai'Sa\", \"Kalista\", \"Karma\", \"Karthus\",\n",
        "    \"Kassadin\", \"Katarina\", \"Kayle\", \"Kayn\", \"Kennen\", \"Kha'Zix\", \"Kindred\", \"Kled\", \"Kog'Maw\", \"LeBlanc\",\n",
        "    \"Lee Sin\", \"Leona\", \"Lillia\", \"Lissandra\", \"Lucian\", \"Lulu\", \"Lux\", \"Malphite\", \"Malzahar\",\n",
        "    \"Maokai\", \"Master Yi\", \"Milio\", \"Miss Fortune\", \"Mordekaiser\", \"Morgana\", \"Naafiri\", \"Nami\",\n",
        "    \"Nasus\", \"Nautilus\", \"Neeko\", \"Nidalee\", \"Nilah\", \"Nocturne\", \"Nunu & Willump\", \"Olaf\", \"Orianna\",\n",
        "    \"Ornn\", \"Pantheon\", \"Poppy\", \"Pyke\", \"Qiyana\", \"Quinn\", \"Rakan\", \"Rammus\", \"Rek'Sai\", \"Rell\",\n",
        "    \"Renata Glasc\", \"Renekton\", \"Rengar\", \"Riven\", \"Rumble\", \"Ryze\", \"Samira\", \"Sejuani\", \"Senna\",\n",
        "    \"Seraphine\", \"Sett\", \"Shaco\", \"Shen\", \"Shyvana\", \"Singed\", \"Sion\", \"Sivir\", \"Skarner\", \"Smolder\", \"Sona\",\n",
        "    \"Soraka\", \"Swain\", \"Sylas\", \"Syndra\", \"Tahm Kench\", \"Taliyah\", \"Talon\", \"Taric\", \"Teemo\",\n",
        "    \"Thresh\", \"Tristana\", \"Trundle\", \"Tryndamere\", \"Twisted Fate\", \"Twitch\", \"Udyr\", \"Urgot\",\n",
        "    \"Varus\", \"Vayne\", \"Veigar\", \"Vel'Koz\", \"Vex\", \"Vi\", \"Viego\", \"Viktor\", \"Vladimir\", \"Volibear\",\n",
        "    \"Warwick\", \"Wukong\", \"Xayah\", \"Xerath\", \"Xin Zhao\", \"Yasuo\", \"Yone\", \"Yorick\", \"Yuumi\",\n",
        "    \"Zac\", \"Zed\", \"Zeri\", \"Ziggs\", \"Zilean\", \"Zoe\", \"Zyra\"\n",
        "]\n",
        "champ_cols = ['pick1', 'pick2', 'pick3', 'pick4', 'pick5']\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "for index, row in merged_result.iterrows():\n",
        "    comp = [row['pick1'], row['pick2'], row['pick3'], row['pick4'], row['pick5']]\n",
        "    bans = [row['ban1'], row['ban2'], row['ban3'], row['ban4'], row['ban5']]\n",
        "    x = []\n",
        "\n",
        "    if row['side'] == \"Blue\":\n",
        "        x.append(0)\n",
        "    else:\n",
        "        x.append(1)\n",
        "\n",
        "    for i in range(5):\n",
        "        champ = comp[i]\n",
        "        if index % 12 == 10:\n",
        "            for j in range(index - 10, index - 5):\n",
        "                if df.iloc[j]['champion'] == champ:\n",
        "                    x.append(player_champ_wr[df.iloc[j]['playerid']][champ][0] / player_champ_wr[df.iloc[j]['playerid']][champ][1])\n",
        "                    x.append(player_career_wr[df.iloc[j]['playerid']][0] / player_career_wr[df.iloc[j]['playerid']][1])\n",
        "                    x.append(champ_wr[champ][0] / champ_wr[champ][1])\n",
        "        else:\n",
        "            for j in range(index - 6, index - 1):\n",
        "                if df.iloc[j]['champion'] == champ:\n",
        "                    x.append(player_champ_wr[df.iloc[j]['playerid']][champ][0] / player_champ_wr[df.iloc[j]['playerid']][champ][1])\n",
        "                    x.append(player_career_wr[df.iloc[j]['playerid']][0] / player_career_wr[df.iloc[j]['playerid']][1])\n",
        "                    x.append(champ_wr[champ][0] / champ_wr[champ][1])\n",
        "\n",
        "    for i in range(5):\n",
        "        if bans[i] not in champ_wr:\n",
        "            x.append(0.5)\n",
        "        else:\n",
        "            x.append(champ_wr[bans[i]][0] / champ_wr[bans[i]][1])\n",
        "    if len(x) == 21:\n",
        "      xs.append(x)\n",
        "      ys.append(row['result'])"
      ],
      "metadata": {
        "id": "wF-weQQW94Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")"
      ],
      "metadata": {
        "id": "hXQZkv1RE9hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2, random_state=42)\n",
        "gb_reg = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_reg.fit(X_train, y_train)\n",
        "y_pred = gb_reg.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")"
      ],
      "metadata": {
        "id": "u-AF3B1UGIvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(xs, ys, test_size=0.2, random_state=42)\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.5f}\")"
      ],
      "metadata": {
        "id": "GnBOD0NRINHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, log_loss, accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "precisionLR, recallLR, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')\n"
      ],
      "metadata": {
        "id": "76IkxOZtXwyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precisionRF, recallRF, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')"
      ],
      "metadata": {
        "id": "hLnVMjM-jN6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_reg = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_reg.fit(X_train, y_train)\n",
        "y_prob = gb_reg.predict_proba(X_test)[:, 1]\n",
        "y_pred = gb_reg.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "precisionGB, recallGB, _ = precision_recall_curve(y_test, y_prob)\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f'F1 Score: {f1}')\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f'AUC: {auc}')"
      ],
      "metadata": {
        "id": "diM6SywIXy3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch > 5:\n",
        "        return lr * 0.5  # Reduce LR after 5 epochs\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "xs = pd.DataFrame(xs)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "def create_more_complex_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Input(shape=(X_train.shape[1],)))\n",
        "\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_more_complex_model()\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=5,          # Stop after 5 epochs without improvement\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stopping, lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot accuracy\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs', fontsize='20')\n",
        "plt.ylabel('Accuracy', fontsize='20')\n",
        "plt.legend(fontsize='14')\n",
        "plt.savefig('teamvector_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs',fontsize='20')\n",
        "plt.ylabel('Loss', fontsize='20')\n",
        "plt.legend(fontsize='14')\n",
        "plt.savefig('teamvector_loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yllMl6Exkosx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisionNN, recallNN, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
        "\n",
        "# Compute ROC-AUC\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "print(f\"AUC: {auc:.2f}\")"
      ],
      "metadata": {
        "id": "X08p6lgMlNEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the precision-recall curve\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 14\n",
        "plt.rcParams['ytick.labelsize'] = 14\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recallLR, precisionLR, label='LR', color='#175E54')\n",
        "plt.plot(recallRF, precisionRF, label='RF', color='#8C1515')\n",
        "plt.plot(recallGB, precisionGB, label='GB', color='#4298B5')\n",
        "plt.plot(recallNN, precisionNN, label='NN', color='#E98300')\n",
        "\n",
        "\n",
        "plt.xlabel('Recall', fontsize='20')\n",
        "plt.ylabel('Precision', fontsize='20')\n",
        "plt.legend(fontsize='16')\n",
        "plt.tight_layout()\n",
        "plt.savefig('teamvector.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dSFsqegGmT2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}